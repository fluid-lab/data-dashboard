# July 25, 2016

After deliberations, we are going to punt on the Vega choice. It turns out, we _can_ use Vega to do sonification. This means the parser isn't fully a blackbox for us. Originally, we believed the Vega parser would munge any data transformations and representations into a form unusable for further Fluid work (eg, sonification). Meaning that any code we wrote from here on out would be entirely specific to Vega's Runtime Parser. 

However, after talking to the Vega community, it turns out the parser can return a *scene graph*. You can learn about it [here](https://github.com/vega/vega-scenegraph/). This gives you svg tags, attributes, and final data points. Using this, sonfication becomes possible, so does further DOM manipulations without Vega's help.

For now, the goal remains to figure out how to make a good UX for selecting fields and other subsets of a full, parsed dataset. Once this is done, it can then use Vega or raw D3 to manipulate the graphcis, but solves a more basic and difficult problem: flexible data manipulation via a GUI. 

I'm going to begin by trying to solve it for 1 or 2 specific representations. If that can work out, we may be able to tease out a more general component for future Fluid work.

Hope to know the answer to that within 2 weeks :)